{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOmYud1YhZePkY0bQ8s1r/Z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jumaantony/Django-Blog-App/blob/master/05_Naive_Bayes/Solution_for_lecture_5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "L0sGPRKA-t6d"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "newsgroups_train = fetch_20newsgroups(subset='train')\n",
        "newsgroups_test = fetch_20newsgroups(subset='test')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(newsgroups_train.data)"
      ],
      "metadata": {
        "id": "RR6UmgB0-9Ge"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "newsgroups_train.target, newsgroups_train.target_names"
      ],
      "metadata": {
        "id": "Y0HSJauV_bXy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "newsgroups_train.data[0]"
      ],
      "metadata": {
        "id": "q2XM9VOI_mcT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_tokens(token_list, text):\n",
        "    for token in token_list:\n",
        "        text = text.replace(token, '')\n",
        "    return text"
      ],
      "metadata": {
        "id": "QxGED-KC_s0p"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from string import punctuation\n",
        "preprocessed_text = [remove_tokens(punctuation, text) for text in newsgroups_train.data]\n",
        "  "
      ],
      "metadata": {
        "id": "Ug6Ne7m2AE2i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assignemnt one\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from string import punctuation\n",
        "preprocessed_text = [remove_tokens(punctuation, text) for text in newsgroups_train.data]\n",
        "  \n",
        "num_word = 30000\n",
        "\n",
        "vectorizer = CountVectorizer(max_features=num_word)\n",
        "train_data = vectorizer.fit_transform(preprocessed_text)"
      ],
      "metadata": {
        "id": "7Pru-tAXAiQD"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_word = train_data.shape[1]"
      ],
      "metadata": {
        "id": "J6dBv8oqBLsQ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assignemnt 2\n",
        "import numpy as np\n",
        "\n",
        "class_freq = np.unique(newsgroups_train.target, return_counts=True)\n",
        "prior_prob = class_freq/np.sum(class_freq)"
      ],
      "metadata": {
        "id": "SFO8p445BPGi"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assignemnt 3\n",
        "data = (train_data > 0).astype('float')\n",
        "word_label_freq = np.zeros((20, num_word))\n",
        "for l in range(20):\n",
        "    ind = newsgroups_train.target == l\n",
        "    word_label_freq[l] = data[ind].sum(axis=0)"
      ],
      "metadata": {
        "id": "G9IC-AheCL1J"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assignment 4\n"
      ],
      "metadata": {
        "id": "83gCnlliClKL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "alpha = 0.01\n",
        "cond_prob = np.array([(word_label_freq[i] + alpha)/(class_freq[i] + num_word * alpha) for i in range(len(class_freq))])\n",
        "   "
      ],
      "metadata": {
        "id": "pMrPyJ6YCrJ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "prior_prob.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sFYLaF9cFmPX",
        "outputId": "5dca17b4-c239-4401-9f29-5161752fe824"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 20)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# assignment 5\n",
        "\n",
        "def find_label(data):\n",
        "    log_prob = np.log(prior_prob)\n",
        "    data = (data > 0).toarray()\n",
        "    in_prob = np.log(cond_prob)\n",
        "    out_prob = np.log(1 - cond_prob)\n",
        "    log_prob += (in_prob * data + out_prob * (1 - data)).sum(axis=1) \n",
        "    return log_prob.argmax()\n",
        "preprocessed_test_text = [remove_tokens(punctuation, text) for text in newsgroups_test.data]\n",
        "test_data = vectorizer.transform(preprocessed_test_text)"
      ],
      "metadata": {
        "id": "YLAlIL7rCurz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = []\n",
        "from tqdm import tqdm\n",
        "for text in tqdm(test_data):\n",
        "    pred.append(find_label(text))"
      ],
      "metadata": {
        "id": "7u2TVVsZGVGC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "metrics.accuracy_score(pred, newsgroups_test.target)"
      ],
      "metadata": {
        "id": "PJL63015GU_G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assignment 6\n",
        "word_label_freq = np.zeros((len(newsgroups_train.target_names),train_data.shape[1]))\n",
        "\n",
        "for i in range(len(newsgroups_train.target)):\n",
        "  word_label_freq[newsgroups_train.target[i]] += train_data[i]\n",
        "\n",
        "word_label_freq\n",
        "print(word_label_freq)"
      ],
      "metadata": {
        "id": "gyCcEmfeGU11"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assignment 7\n",
        "num_word_in_classes = np.sum(word_label_freq,axis=1)\n",
        "print(num_word_in_classes)\n",
        "     "
      ],
      "metadata": {
        "id": "zrabehzYIvdk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assignment 8\n",
        "log_cond_prob = np.array([np.log(word_label_freq[i] + alpha) - np.log(num_word_in_classes[i] + num_word * alpha) for i in range(len(class_freq))])\n"
      ],
      "metadata": {
        "id": "WHxjwWMEIvTL"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assignment 9\n",
        "log_prior_prob = np.log(prior_prob)\n",
        "def find_label(data):\n",
        "    log_prob = log_prior_prob.copy()\n",
        "    data = data.toarray()\n",
        "    log_prob += (log_cond_prob.copy() * data).sum(axis=1)\n",
        "    return log_prob.argmax()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ULhrBwFDIvHO",
        "outputId": "d44e273c-9e9b-48f0-b7db-c8dbbaf36557"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-31-7afea8c5fc73>:2: RuntimeWarning: divide by zero encountered in log\n",
            "  log_prior_prob = np.log(prior_prob)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = vectorizer.transform(preprocessed_test_text)"
      ],
      "metadata": {
        "id": "2X10yCF5Iu9W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = []\n",
        "for text in tqdm(test_data):\n",
        "    pred.append(find_label(text))\n",
        "metrics.accuracy_score(pred, newsgroups_test.target)"
      ],
      "metadata": {
        "id": "lrnylxcBIunp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}